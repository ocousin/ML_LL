{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "#from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.stats\n",
    "from hyperopt import hp, tpe, fmin, Trials, STATUS_OK\n",
    "from hyperopt.pyll.base import scope\n",
    "import seaborn as sns\n",
    "from matplotlib import cm, pyplot as plt\n",
    "from scipy import stats as st\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import brevitas.nn as qnn\n",
    "from brevitas.quant import Int8WeightPerTensorFixedPoint as WeightQuant\n",
    "from brevitas.quant import Int8ActPerTensorFixedPoint as ActQuant\n",
    "from brevitas.quant import Int8BiasPerTensorFixedPointInternalScaling as BiasQuant\n",
    "from brevitas.export import PyXIRManager\n",
    "from brevitas.export import FINNManager\n",
    "from preProcessing import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORDER BOOK DATA\n",
    "Getting the Data\n",
    "Letâ€™s download the data samples from LOBSTER. This service provides Google, Apple, Amazon, Intel, Microsoft assets as an examples with 3 levels as market depth (1, 5, 10 levels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORDER BOOK\n",
      "data1.shape =  (118496, 4)\n",
      "   5859400  200  5853300  18\n",
      "0  5859100   18  5853300  18\n",
      "1  5859200   18  5853300  18\n",
      "2  5859300  100  5853300  18\n",
      "3  5859300  100  5853600  18\n",
      "4  5859300  100  5857300  20\n",
      "MESSAGES\n",
      "data2.shape =  (118496, 4)\n",
      "   34200.004241176  1  16113575  18  5853300  1.1\n",
      "0     34200.025552  1  16120456  18  5859100   -1\n",
      "1     34200.201743  3  16120456  18  5859100   -1\n",
      "2     34200.201781  3  16120480  18  5859200   -1\n",
      "3     34200.205573  1  16167159  18  5853600    1\n",
      "4     34200.271740  1   3647217  20  5857300    1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "RANDOM_SEED = 42\n",
    "## reading csv files and format the data adding column names\n",
    "## set Asset and level \n",
    "asset = 'AAPL'\n",
    "level = 1     # Can only be 1, 5 and 10\n",
    "\n",
    "data1 = loadDataOrderBook('../../Data/{0}_2012-06-21_34200000_57600000_orderbook_{1}.csv', asset, level)\n",
    "data2 = loadDataMessage('../../Data/{0}_2012-06-21_34200000_57600000_message_{1}.csv', asset, level)\n",
    "\n",
    "# displaying input files\n",
    "print(\"ORDER BOOK\")\n",
    "print(\"data1.shape = \", data1.shape)\n",
    "print(data1.head())\n",
    "\n",
    "print(\"MESSAGES\")\n",
    "print(\"data2.shape = \", data1.shape)\n",
    "print(data2.head())\n",
    "\n",
    "data1.columns=[\"ask\", \"volume_ask\", \"bid\", \"volume_bid\"]\n",
    "data2.columns=[\"Time\", \"Type\", \"OrderID\", \"Size\", \"Price\", \"Direction\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging of the order Book and the Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "Shape of the result matrix is =  (118496, 8)\n",
      "       ask  volume_ask      bid  volume_bid  Type  Size    Price  Direction\n",
      "0  5859100          18  5853300          18     1    18  5859100        0.1\n",
      "1  5859200          18  5853300          18     3    18  5859100        0.1\n",
      "2  5859300         100  5853300          18     3    18  5859200        0.1\n",
      "3  5859300         100  5853600          18     1    18  5853600        0.9\n",
      "4  5859300         100  5857300          20     1    20  5857300        0.9\n",
      "number of rows = 118496\n",
      "number of columns = 8\n",
      "Number of inputs for each categories\n"
     ]
    }
   ],
   "source": [
    "#Change the output format to be between 0.1 & 0.9 instead of -1 & 1\n",
    "result_high=0.9\n",
    "result_low=1-result_high\n",
    "\n",
    "# using merge function by setting how='outer'\n",
    "result = data1.merge(data2, left_index=True, right_index=True, how='left')\n",
    "result['Direction'].replace({-1 : result_low, 1 : result_high}, inplace=True)\n",
    "\n",
    "cols = [\"ask\", \"volume_ask\", \"bid\", \"volume_bid\", \"Type\", \"Size\", \"Price\", \"Direction\"]\n",
    "result = result[cols]\n",
    "\n",
    "print(\"RESULTS\")  \n",
    "# displaying result\n",
    "print(\"Shape of the result matrix is = \",result.shape)\n",
    "print(result.head())\n",
    "\n",
    "print(\"number of rows =\",result.shape[0])\n",
    "print(\"number of columns =\",result.shape[1])\n",
    "print(\"Number of inputs for each categories\")\n",
    "#result.Type_1.value_counts()/result.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Network Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the matrix X is:\t (118496, 7)\n",
      "Shape of the matrix Y is:\t (118496, 1) \n",
      "\n",
      "INPUT VALUES TO FEED THE CNN\n",
      "       ask  volume_ask      bid  volume_bid  Type  Size    Price\n",
      "0  5859100          18  5853300          18     1    18  5859100\n",
      "OUTPUT VALUES FOR TRAINING\n",
      "   Direction\n",
      "0        0.1\n"
     ]
    }
   ],
   "source": [
    "#Creating the 7 Inputs for the DNN \n",
    "X = result[[\"ask\", \"volume_ask\", \"bid\", \"volume_bid\", \"Type\", \"Size\", \"Price\"]]\n",
    "print(\"Shape of the matrix X is:\\t\",X.shape)\n",
    "\n",
    "#Creating the 1 output for the DNN to train the network with results \n",
    "Y = result[[\"Direction\"]]\n",
    "print(\"Shape of the matrix Y is:\\t\",Y.shape,\"\\n\")\n",
    "\n",
    "##pre-processing\n",
    "print(\"INPUT VALUES TO FEED THE CNN\")\n",
    "print(X.head(1))\n",
    "print(\"OUTPUT VALUES FOR TRAINING\")\n",
    "print(Y.head(1))\n",
    "\n",
    "#Normalise the INPUT value to improve the learning\n",
    "X=preprocess(1)(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPLIT DATA FOR TRAINING AND TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the matrix X_train_np is:\t (94796, 7)\n",
      "Shape of the matrix Y_train_np is:\t (94796, 1)\n",
      "Shape of the matrix X_test_np is:\t (23700, 7) \n",
      "\n",
      "Shape of the matrix Y_test_np is:\t (23700, 1) \n",
      "\n",
      "INPUT             ask  volume_ask       bid  volume_bid      Type      Size  \\\n",
      "94796 -1.204252    0.098682 -1.210559   -0.032607 -0.998848  0.934232   \n",
      "\n",
      "          Price  \n",
      "94796 -1.228414  \n",
      "OUTPUT        Direction\n",
      "94796        0.9\n",
      "Convert Numpy array to Torch\n",
      "\n",
      "Dimension of input tensor: 2\n",
      "Input tensor Size:\n",
      " torch.Size([94796, 7])\n",
      "Dimension of input tensor: 1\n",
      "Input tensor Size:\n",
      " torch.Size([94796])\n",
      "Shape of the matrix X_train_T is:\t torch.Size([94796, 7])\n",
      "Shape of the matrix X_test_T is:\t torch.Size([23700, 7]) \n",
      "\n",
      "Shape of the matrix Y_train_T is:\t torch.Size([94796])\n",
      "Shape of the matrix Y_test_T is:\t torch.Size([23700]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Split the data between trianing 80% and test 20% no shuffling as it is a time series\n",
    "#0.2 = 20% of the data for test\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "X_train_np, X_test_np, Y_train_np, Y_test_np = train_test_split(X, Y, test_size=0.2, shuffle = False, stratify = None)\n",
    "print(\"Shape of the matrix X_train_np is:\\t\",X_train_np.shape)\n",
    "print(\"Shape of the matrix Y_train_np is:\\t\",Y_train_np.shape)\n",
    "print(\"Shape of the matrix X_test_np is:\\t\",X_test_np.shape,\"\\n\")\n",
    "print(\"Shape of the matrix Y_test_np is:\\t\",Y_test_np.shape,\"\\n\")\n",
    "\n",
    "#checking the X_test_np data\n",
    "print(\"INPUT\",X_test_np.head(1))\n",
    "\n",
    "#checking the Y_test_np data\n",
    "print(\"OUTPUT\",Y_test_np.head(1))\n",
    "\n",
    "print('Convert Numpy array to Torch\\n')\n",
    "#_T for Torch arrays\n",
    "X_train_T = torch.from_numpy(X_train_np.to_numpy()).float()\n",
    "\n",
    "print(\"Dimension of input tensor:\", X_train_T.dim())\n",
    "print(\"Input tensor Size:\\n\",X_train_T.size())\n",
    "\n",
    "\n",
    "#remove a dimension\n",
    "Y_train_T = torch.squeeze(torch.from_numpy(Y_train_np.to_numpy()).float())\n",
    "X_test_T = torch.from_numpy(X_test_np.to_numpy()).float()\n",
    "Y_test_T = torch.squeeze(torch.from_numpy(Y_test_np.to_numpy()).float())\n",
    "\n",
    "print(\"Dimension of input tensor:\", Y_train_T.dim())\n",
    "print(\"Input tensor Size:\\n\",Y_train_T.size())\n",
    "print(\"Shape of the matrix X_train_T is:\\t\",X_train_T.shape)\n",
    "print(\"Shape of the matrix X_test_T is:\\t\",X_test_T.shape,\"\\n\")\n",
    "print(\"Shape of the matrix Y_train_T is:\\t\",Y_train_T.shape)\n",
    "print(\"Shape of the matrix Y_test_T is:\\t\",Y_test_T.shape,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building of the Pytorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base network\n",
    "class Net(nn.Module):\n",
    "  def __init__(self, n_features):\n",
    "    super(Net, self).__init__()\n",
    "    self.fc1 = nn.Linear(n_features, 7)\n",
    "    self.fc2 = nn.Linear(7, 20)\n",
    "    self.fc3 = nn.Linear(20, 1)\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    return torch.sigmoid(self.fc3(x))*(result_high-result_low)+result_low\n",
    "\n",
    "net = Net(X_train_T.shape[1])\n",
    "#print(X_train_T.shape[1])\n",
    "#print(\"NN structure is: \",net)\n",
    "#print(net.parameters)\n",
    "\n",
    "#augmented network\n",
    "class Net1(nn.Module):\n",
    "  def __init__(self, n_features):\n",
    "    super(Net1, self).__init__()\n",
    "    self.fc1 = nn.Linear(n_features, 7)\n",
    "    self.fc2 = nn.Linear(7, 20)\n",
    "    self.fc4 = nn.Linear(20, 20)\n",
    "    self.fc5 = nn.Linear(20, 20)\n",
    "    self.fc3 = nn.Linear(20, 1)\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = F.relu(self.fc4(x))\n",
    "    #x = F.relu(self.fc5(x))\n",
    "    return (torch.sigmoid(self.fc3(x))*(result_high-result_low)+result_low)\n",
    "\n",
    "net1 = Net1(X_train_T.shape[1])\n",
    "#print(X_train_T.shape[1])\n",
    "#print(\"NN structure is: \",net1)\n",
    "#print(net1.parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantized the Network using Brevitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q_bit_width=3\n",
    "\n",
    "#quantized network\n",
    "class QuantWeightNet(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(QuantWeightNet, self).__init__()\n",
    "        self.fc1   = qnn.QuantLinear(n_features, 7, bias=True, weight_bit_width=q_bit_width)\n",
    "        self.relu1 = qnn.QuantReLU()\n",
    "        self.fc2   = qnn.QuantLinear(7, 20, bias=True, weight_bit_width=q_bit_width)\n",
    "        self.relu2 = qnn.QuantReLU()\n",
    "        self.fc4   = qnn.QuantLinear(20, 20, bias=True, weight_bit_width=q_bit_width)\n",
    "        self.relu3 = qnn.QuantReLU()\n",
    "        self.fc5   = qnn.QuantLinear(20, 20, bias=True, weight_bit_width=q_bit_width)\n",
    "        self.relu4 = qnn.QuantReLU()\n",
    "        self.fc3   = qnn.QuantLinear(7, 1, bias=False, weight_bit_width=q_bit_width)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.relu1(self.fc1(x))\n",
    "        #x = self.relu2(self.fc2(x))\n",
    "        #x = self.relu3(self.fc4(x))\n",
    "        #x = self.relu4(self.fc5(x))\n",
    "        #return (torch.sigmoid(self.fc3(x))*(result_high-result_low)+result_low)\n",
    "\n",
    "        return ((self.fc3(x))*(result_high-result_low)+result_low)\n",
    "\n",
    "\n",
    "net_q= QuantWeightNet(X_train_T.shape[1])\n",
    "#print(X_train_T.shape[1])\n",
    "#print(\"NN structure is: \",net_q)\n",
    "#print(net_q.parameters)    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([94796, 7])\n",
      "torch.Size([23700, 7])\n",
      "torch.Size([94796])\n",
      "torch.Size([23700])\n"
     ]
    }
   ],
   "source": [
    "#Creates a criterion that measures the Binary Cross Entropy between the target and the input probabilities\n",
    "criterion = nn.BCELoss(weight=None, size_average=None, reduce=None, reduction='mean')\n",
    "\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "optimizer1 = optim.Adam(net1.parameters(), lr=0.0003)\n",
    "optimizer_q = optim.Adam(net_q.parameters(), lr=0.0003)\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#transfer data to the GPU\n",
    "X_train = X_train_T.to(device)\n",
    "Y_train = Y_train_T.to(device)\n",
    "X_test = X_test_T.to(device)\n",
    "Y_test = Y_test_T.to(device)\n",
    "\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "net = net.to(device)\n",
    "net1 = net1.to(device)\n",
    "net_q = net_q.to(device)\n",
    "\n",
    "device\n",
    "#print(list(net.parameters()))\n",
    "#print(optimizer.param_groups)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "#print(optimizer1.param_groups)\n",
    "#print(optimizer_q.param_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving network model and export as Onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done saving net\n",
      "Done saving Q net\n",
      "tensor([[[[ 0.2431, -0.4371,  0.8412,  0.1157, -0.1811,  2.9313, -0.3533]]]])\n",
      "torch.Size([1, 1, 1, 7])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bowenpyk/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1365: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#FINNManager.export(net_q, input_shape=(1, 1, 1, 7), export_path='finn_qnet.onnx')\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#from brevitas.export import export_brevitas_onnx\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#export_brevitas_onnx(net_q, input_t=inp, export_path='finn_qnet.onnx')\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbrevitas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexport\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m export_finn_onnx\n\u001b[0;32m---> 28\u001b[0m \u001b[43mexport_finn_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet_q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_t\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfinn_qnet.onnx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/brevitas/export/__init__.py:14\u001b[0m, in \u001b[0;36mexport_finn_onnx\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(FINNManager\u001b[38;5;241m.\u001b[39mexport)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexport_finn_onnx\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFINNManager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/brevitas/export/onnx/finn/manager.py:125\u001b[0m, in \u001b[0;36mFINNManager.export\u001b[0;34m(cls, module, input_shape, export_path, input_t, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m     module \u001b[38;5;241m=\u001b[39m Sequential(preprocessing_module, module)\n\u001b[1;32m    124\u001b[0m     module\u001b[38;5;241m.\u001b[39mtrain(training_state)\n\u001b[0;32m--> 125\u001b[0m onnx_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_onnx\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(input_t, QuantTensor):\n\u001b[1;32m    128\u001b[0m     bit_width \u001b[38;5;241m=\u001b[39m input_t\u001b[38;5;241m.\u001b[39mbit_width\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/brevitas/export/onnx/manager.py:99\u001b[0m, in \u001b[0;36mONNXBaseManager.export_onnx\u001b[0;34m(cls, module, input_shape, export_path, input_t, disable_warnings, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m         input_t \u001b[38;5;241m=\u001b[39m (input_t,)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# enable export mode, this triggers collecting export values into handlers\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_export_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menabled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# temporarily disable input caching to avoid collectives empty debug values\u001b[39;00m\n\u001b[1;32m    101\u001b[0m module\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m m: _override_inp_caching_mode(m, enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:668\u001b[0m, in \u001b[0;36mModule.apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;124;03mas well as self. Typical use includes initializing the parameters of a model\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;124;03m(see also :ref:`nn-init-doc`).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;124;03m    )\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 668\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    669\u001b[0m fn(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:669\u001b[0m, in \u001b[0;36mModule.apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m    668\u001b[0m     module\u001b[38;5;241m.\u001b[39mapply(fn)\n\u001b[0;32m--> 669\u001b[0m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/brevitas/export/onnx/manager.py:99\u001b[0m, in \u001b[0;36mONNXBaseManager.export_onnx.<locals>.<lambda>\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m     97\u001b[0m         input_t \u001b[38;5;241m=\u001b[39m (input_t,)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# enable export mode, this triggers collecting export values into handlers\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m module\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m m: \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_export_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menabled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# temporarily disable input caching to avoid collectives empty debug values\u001b[39;00m\n\u001b[1;32m    101\u001b[0m module\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m m: _override_inp_caching_mode(m, enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/brevitas/export/onnx/finn/manager.py:104\u001b[0m, in \u001b[0;36mFINNManager.set_export_mode\u001b[0;34m(cls, module, enabled)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_export_mode\u001b[39m(\u001b[38;5;28mcls\u001b[39m, module: Module, enabled: \u001b[38;5;28mbool\u001b[39m):\n\u001b[0;32m--> 104\u001b[0m     \u001b[43m_set_layer_export_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/brevitas/export/manager.py:100\u001b[0m, in \u001b[0;36m_set_layer_export_mode\u001b[0;34m(m, enabled)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_layer_export_mode\u001b[39m(m: Module, enabled: \u001b[38;5;28mbool\u001b[39m):\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, QuantLayerMixin) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexport_mode\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 100\u001b[0m         m\u001b[38;5;241m.\u001b[39mexport_mode \u001b[38;5;241m=\u001b[39m enabled\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1255\u001b[0m, in \u001b[0;36mModule.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1253\u001b[0m     buffers[name] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1255\u001b[0m     \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/brevitas/nn/mixin/base.py:167\u001b[0m, in \u001b[0;36mQuantLayerMixin.export_mode\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m  \u001b[38;5;66;03m# don't set export mode when it's not required and there is no handler\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m value \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexport_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_for_export\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexport_handler\u001b[38;5;241m.\u001b[39mattach_debug_info(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexport_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/brevitas/export/onnx/finn/handler/act.py:48\u001b[0m, in \u001b[0;36mFINNQuantReLUHandler.prepare_for_export\u001b[0;34m(self, module)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_for_export\u001b[39m(\u001b[38;5;28mself\u001b[39m, module: QuantReLU):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbolic_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqnt_type\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_type(module),\n\u001b[0;32m---> 48\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthres\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthresholds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquant_act_scale(module)}\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/brevitas/export/onnx/finn/handler/act.py:34\u001b[0m, in \u001b[0;36mFINNQuantReLUHandler.thresholds\u001b[0;34m(module, extend_tensor_to_channels)\u001b[0m\n\u001b[1;32m     32\u001b[0m         thresholds[c][t] \u001b[38;5;241m=\u001b[39m min_threshold[c] \u001b[38;5;241m+\u001b[39m step[c] \u001b[38;5;241m*\u001b[39m t\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extend_tensor_to_channels:\n\u001b[0;32m---> 34\u001b[0m     output_channels \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cached_inp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     35\u001b[0m     final_shape \u001b[38;5;241m=\u001b[39m (output_channels, num_thresholds)\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m thresholds\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m final_shape:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = 'model1.pt'\n",
    "torch.save(net1, MODEL_PATH)\n",
    "#net1 = torch.load(MODEL_PATH)\n",
    "print(\"Done saving net\")\n",
    "\n",
    "MODEL_PATH = 'model_q.pt'\n",
    "torch.save(net_q.state_dict(), MODEL_PATH)\n",
    "#net_q = torch.load(MODEL_PATH)\n",
    "print(\"Done saving Q net\")\n",
    "\n",
    "\n",
    "inp=torch.empty((1,1,1,7))\n",
    "inp=torch.randn(1,1,1,7)\n",
    "#inp = torch.tensor((1,1,1,7))\n",
    "\n",
    "#print(inp)\n",
    "print(inp.shape)\n",
    "\n",
    "\n",
    "#FINNManager.export(net_q, input_shape=(1, 1, 1, 7), export_path='finn_qnet.onnx')\n",
    "\n",
    "#from brevitas.export import export_brevitas_onnx\n",
    "\n",
    "#export_brevitas_onnx(net_q, input_t=inp, export_path='finn_qnet.onnx')\n",
    "\n",
    "from brevitas.export import export_finn_onnx\n",
    "\n",
    "export_finn_onnx(net_q, input_t=inp, export_path='finn_qnet.onnx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "  Train set - loss: 0.69204, accuracy: 0.52938\n",
      "  Test  set - loss: 0.6958, accuracy: 0.457\n",
      "  \n",
      "epoch 0\n",
      "  QTrain set - loss: 0.69241, accuracy: 0.52938\n",
      "  QTest  set - loss: 0.69497, accuracy: 0.45772\n",
      "  \n",
      "epoch 100\n",
      "  Train set - loss: 0.68978, accuracy: 0.52129\n",
      "  Test  set - loss: 0.69405, accuracy: 0.44464\n",
      "  \n",
      "epoch 100\n",
      "  QTrain set - loss: 0.69068, accuracy: 0.52129\n",
      "  QTest  set - loss: 0.6979, accuracy: 0.45772\n",
      "  \n",
      "epoch 200\n",
      "  Train set - loss: 0.68659, accuracy: 0.47085\n",
      "  Test  set - loss: 0.68881, accuracy: 0.27156\n",
      "  \n",
      "epoch 200\n",
      "  QTrain set - loss: 0.68842, accuracy: 0.47085\n",
      "  QTest  set - loss: 0.69685, accuracy: 0.39325\n",
      "  \n",
      "epoch 300\n",
      "  Train set - loss: 0.68121, accuracy: 0.45888\n",
      "  Test  set - loss: 0.68355, accuracy: 0.23738\n",
      "  \n",
      "epoch 300\n",
      "  QTrain set - loss: 0.68594, accuracy: 0.45888\n",
      "  QTest  set - loss: 0.6928, accuracy: 0.30519\n",
      "  \n",
      "epoch 400\n",
      "  Train set - loss: 0.67177, accuracy: 0.42214\n",
      "  Test  set - loss: 0.6787, accuracy: 0.2681\n",
      "  \n",
      "epoch 400\n",
      "  QTrain set - loss: 0.68284, accuracy: 0.42214\n",
      "  QTest  set - loss: 0.68574, accuracy: 0.23321\n",
      "  \n",
      "epoch 500\n",
      "  Train set - loss: 0.65722, accuracy: 0.42624\n",
      "  Test  set - loss: 0.66985, accuracy: 0.26118\n",
      "  \n",
      "epoch 500\n",
      "  QTrain set - loss: 0.6736, accuracy: 0.42624\n",
      "  QTest  set - loss: 0.67789, accuracy: 0.24561\n",
      "  \n",
      "epoch 600\n",
      "  Train set - loss: 0.63, accuracy: 0.42539\n",
      "  Test  set - loss: 0.6647, accuracy: 0.31439\n",
      "  \n",
      "epoch 600\n",
      "  QTrain set - loss: 0.66552, accuracy: 0.42539\n",
      "  QTest  set - loss: 0.69401, accuracy: 0.36494\n",
      "  \n",
      "epoch 700\n",
      "  Train set - loss: 0.58427, accuracy: 0.44366\n",
      "  Test  set - loss: 0.65237, accuracy: 0.35397\n",
      "  \n",
      "epoch 700\n",
      "  QTrain set - loss: 0.66612, accuracy: 0.44366\n",
      "  QTest  set - loss: 0.73997, accuracy: 0.39992\n",
      "  \n",
      "epoch 800\n",
      "  Train set - loss: 0.52246, accuracy: 0.47118\n",
      "  Test  set - loss: 0.62874, accuracy: 0.37097\n",
      "  \n",
      "epoch 800\n",
      "  QTrain set - loss: 0.65674, accuracy: 0.47118\n",
      "  QTest  set - loss: 0.68298, accuracy: 0.20945\n",
      "  \n",
      "epoch 900\n",
      "  Train set - loss: 0.46296, accuracy: 0.49655\n",
      "  Test  set - loss: 0.56008, accuracy: 0.38527\n",
      "  \n",
      "epoch 900\n",
      "  QTrain set - loss: 0.65177, accuracy: 0.49655\n",
      "  QTest  set - loss: 0.68271, accuracy: 0.27899\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000):\n",
    "      optimizer1.zero_grad() #reset Gradient descent\n",
    "      optimizer_q.zero_grad()      \n",
    "      Y_pred = net1(X_train)\n",
    "      Y_pred_q = net_q(X_train)\n",
    "      Y_pred = torch.squeeze(Y_pred)\n",
    "      Y_pred_q = torch.squeeze(Y_pred_q)\n",
    "      criterion=nn.BCELoss()\n",
    "      train_loss = criterion(Y_pred, Y_train)\n",
    "      train_loss_q = criterion(Y_pred_q, Y_train)\n",
    "      train_loss.backward() #propagate the error currently making     \n",
    "      optimizer1.step()      #optimise \n",
    "      train_loss_q.backward() #propagate the error currently making     \n",
    "      optimizer_q.step()\n",
    "\n",
    "      if epoch % 100==0:\n",
    "        train_acc = calculate_accuracy(Y_train, Y_pred,result_high,result_low)\n",
    "        train_acc_q = calculate_accuracy(Y_train, Y_pred,result_high,result_low)\n",
    "        Y_test_pred = net1(X_test)\n",
    "        Y_test_pred = torch.squeeze(Y_test_pred)\n",
    "        test_loss = criterion(Y_test_pred, Y_test)\n",
    "        test_acc = calculate_accuracy(Y_test, Y_test_pred,result_high,result_low)\n",
    "        print(\n",
    "  f'''epoch {epoch}\n",
    "  Train set - loss: {round_tensor(train_loss)}, accuracy: {round_tensor(train_acc)}\n",
    "  Test  set - loss: {round_tensor(test_loss)}, accuracy: {round_tensor(test_acc)}\n",
    "  ''')\n",
    "        Y_test_pred_q = net_q(X_test)\n",
    "        Y_test_pred_q = torch.squeeze(Y_test_pred_q)\n",
    "        test_loss_q = criterion(Y_test_pred_q, Y_test)\n",
    "        test_acc_q = calculate_accuracy(Y_test, Y_test_pred_q,result_high,result_low)\n",
    "        print(\n",
    "  f'''epoch {epoch}\n",
    "  QTrain set - loss: {round_tensor(train_loss_q)}, accuracy: {round_tensor(train_acc_q)}\n",
    "  QTest  set - loss: {round_tensor(test_loss_q)}, accuracy: {round_tensor(test_acc_q)}\n",
    "  ''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f424044f726a0a17493f0821198c6b0838cadd57ed83ee9b306874a951ffce3d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
